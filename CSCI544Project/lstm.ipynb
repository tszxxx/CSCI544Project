{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from numpy import random\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.1.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_model = Word2Vec.load('pad_word2vec_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>descriptions</th>\n",
       "      <th>scores</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;START&gt; 摇 摇 摇 外婆桥 1930 年代 乡村 少年 唐 水生 来到 上海 投靠 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;START&gt; 向日葵 本片 延续 张扬 洗澡 昨天 影片 呈现 中国式 父子 冲突 和解 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;START&gt; 囧 &lt;UNK&gt; 囧 商业 &lt;UNK&gt; &lt;UNK&gt; 五年 时间 发明 一种 油...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;START&gt; 少林寺 &lt;UNK&gt; 末年 隋 &lt;UNK&gt; 侄子 王仁则 &lt;UNK&gt; &lt;UNK...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;START&gt; 斗地主 故事 发生 民国初年 春天 青楼 当红 头牌 无数 男人 &lt;UNK&gt;...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        descriptions  scores\n",
       "0  <START> 摇 摇 摇 外婆桥 1930 年代 乡村 少年 唐 水生 来到 上海 投靠 ...       1\n",
       "1  <START> 向日葵 本片 延续 张扬 洗澡 昨天 影片 呈现 中国式 父子 冲突 和解 ...       1\n",
       "2  <START> 囧 <UNK> 囧 商业 <UNK> <UNK> 五年 时间 发明 一种 油...       1\n",
       "3  <START> 少林寺 <UNK> 末年 隋 <UNK> 侄子 王仁则 <UNK> <UNK...       1\n",
       "4  <START> 斗地主 故事 发生 民国初年 春天 青楼 当红 头牌 无数 男人 <UNK>...       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('processed_data.csv')\n",
    "data = data[['descriptions', 'scores']]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data):\n",
    "    test_index = random.choice(range(len(data)), data.shape[0] // 4)\n",
    "    test_data = data[data.index.isin(test_index)]\n",
    "    train_data = data[~data.index.isin(test_index)]\n",
    "    return train_data, test_data\n",
    "\n",
    "train_data, test_data = train_test_split(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 100)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab = {word: index for index, word in enumerate(wv_model.wv.index2word)}\n",
    "reverse_vocab = {index: word for index, word in enumerate(wv_model.wv.index2word)}\n",
    "\n",
    "embedding_matrix = wv_model.wv.vectors\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "unk_index = vocab['<UNK>']\n",
    "def transform_data(sentence,vocab):\n",
    "    words=sentence.split(' ')\n",
    "    idxs=[vocab[word] if word in vocab else unk_index for word in words]\n",
    "    return idxs\n",
    "\n",
    "train_idxs = train_data.apply(lambda x:transform_data(x[0],vocab), axis = 1)\n",
    "test_idxs = test_data.apply(lambda x:transform_data(x[0],vocab), axis = 1)\n",
    "all_idxs = data.apply(lambda x:transform_data(x[0],vocab), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [30484, 8257, 8257, 8257, 20411, 7047, 159, 81...\n",
       "1    [30484, 15250, 37, 1456, 2590, 9855, 7048, 16,...\n",
       "2    [30484, 1607, 30485, 1607, 3043, 30485, 30485,...\n",
       "3    [30484, 3046, 30485, 1699, 9858, 30485, 3604, ...\n",
       "5    [30484, 2799, 2800, 20442, 1033, 2273, 186, 30...\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_idxs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.array(train_idxs.tolist())\n",
    "test_x = np.array(test_idxs.tolist())\n",
    "all_x = np.array(all_idxs.tolist())\n",
    "train_label = np.array(train_data['scores'].values)\n",
    "test_label = np.array(test_data['scores'].values)\n",
    "all_label = np.array(data['scores'].values)\n",
    "label_list = [train_label, test_label, all_label]\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_label = encoder.fit_transform(train_label)\n",
    "encoder = LabelEncoder()\n",
    "test_label = encoder.fit_transform(test_label)\n",
    "encoder = LabelEncoder()\n",
    "all_label = encoder.fit_transform(all_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[30484,  8257,  8257, ..., 30487, 30487, 30487],\n",
       "       [30484, 15250,    37, ..., 30487, 30487, 30487],\n",
       "       [30484,  1607, 30485, ..., 30487, 30487, 30487],\n",
       "       ...,\n",
       "       [30484, 14864, 30485, ..., 30487, 30487, 30487],\n",
       "       [30484, 30485,  4319, ..., 30487, 30487, 30487],\n",
       "       [30484, 30485,    37, ..., 30487, 30487, 30487]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import LSTM, Input, Dense, Activation, RepeatVector, Bidirectional\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import binary_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_classifier(input_length, vocab_size, embedding_matrix = np.array([])):\n",
    "    model = Sequential()\n",
    "    if len(embedding_matrix):\n",
    "        model.add(Embedding(input_dim = vocab_size, output_dim = 100, weights=[embedding_matrix], trainable=False,\n",
    "                        input_length=input_length))\n",
    "    else:\n",
    "        model.add(Embedding(input_dim = vocab_size, output_dim = 100))\n",
    "    model.add(Bidirectional(LSTM(128, dropout = 0.2, recurrent_dropout=0.2)))\n",
    "    model.add(Dense(2))\n",
    "    model.add(Activation('softmax'))\n",
    "#     optimizer = Adam(learning_rate = 1e-5)\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    model.compile(loss = loss_object, optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30490, 100)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length = train_x.shape[1]\n",
    "vocab_size = len(vocab)\n",
    "embedding_matrix = wv_model.wv.vectors\n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "353"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 100)         3049000   \n",
      "_________________________________________________________________\n",
      "bidirectional (Bidirectional (None, 256)               234496    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 2)                 0         \n",
      "=================================================================\n",
      "Total params: 3,284,010\n",
      "Trainable params: 3,284,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = build_classifier(input_length, vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2223 samples, validate on 612 samples\n",
      "Epoch 1/10\n",
      "2223/2223 - 57s - loss: 0.6888 - accuracy: 0.7049 - val_loss: 0.6853 - val_accuracy: 0.7239\n",
      "Epoch 2/10\n",
      "2223/2223 - 54s - loss: 0.6803 - accuracy: 0.7395 - val_loss: 0.6770 - val_accuracy: 0.7239\n",
      "Epoch 3/10\n",
      "2223/2223 - 53s - loss: 0.6705 - accuracy: 0.7395 - val_loss: 0.6670 - val_accuracy: 0.7239\n",
      "Epoch 4/10\n",
      "2223/2223 - 53s - loss: 0.6579 - accuracy: 0.7395 - val_loss: 0.6528 - val_accuracy: 0.7239\n",
      "Epoch 5/10\n",
      "2223/2223 - 55s - loss: 0.6377 - accuracy: 0.7395 - val_loss: 0.6285 - val_accuracy: 0.7239\n",
      "Epoch 6/10\n",
      "2223/2223 - 55s - loss: 0.6029 - accuracy: 0.7395 - val_loss: 0.5941 - val_accuracy: 0.7239\n",
      "Epoch 7/10\n",
      "2223/2223 - 55s - loss: 0.5831 - accuracy: 0.7395 - val_loss: 0.5907 - val_accuracy: 0.7239\n",
      "Epoch 8/10\n",
      "2223/2223 - 54s - loss: 0.5797 - accuracy: 0.7395 - val_loss: 0.5901 - val_accuracy: 0.7239\n",
      "Epoch 9/10\n",
      "2223/2223 - 56s - loss: 0.5767 - accuracy: 0.7395 - val_loss: 0.5894 - val_accuracy: 0.7239\n",
      "Epoch 10/10\n",
      "2223/2223 - 55s - loss: 0.5753 - accuracy: 0.7395 - val_loss: 0.5892 - val_accuracy: 0.7239\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "history = model.fit(train_x, train_label, \n",
    "                    epochs = num_epochs, \n",
    "                    validation_data=(test_x, test_label), \n",
    "                    verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string])\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()\n",
    "    return\n",
    "\n",
    "plot_graphs(history, \"loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/612 [==============================] - 1s 2ms/sample - loss: 0.5892 - accuracy: 0.7239\n",
      "test loss, test acc: [0.5892490127117805, 0.7238562]\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_x, test_label)\n",
    "print('test loss, test acc:', results)\n",
    "predictions = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7395411605937922"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_label) / len(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01612051, 0.9838795 ],\n",
       "       [0.01521815, 0.98478186],\n",
       "       [0.0152934 , 0.9847066 ],\n",
       "       ...,\n",
       "       [0.01663435, 0.9833657 ],\n",
       "       [0.01654886, 0.9834511 ],\n",
       "       [0.01623786, 0.9837622 ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "345"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
